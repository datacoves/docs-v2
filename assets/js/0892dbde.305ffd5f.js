"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7361],{28453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var o=t(96540);const r={},s=o.createContext(r);function i(e){const n=o.useContext(s);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(s.Provider,{value:n},e.children)}},33768:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"how-tos/airflow/run-dbt","title":"DAGs - Run dbt","description":"Airflow synchronizes a git repository\'s configured git branch every minute. (The branch specified in  the Git branch name field in the environment\'s DAGs sync configuration)","source":"@site/docs/how-tos/airflow/run-dbt.md","sourceDirName":"how-tos/airflow","slug":"/how-tos/airflow/run-dbt","permalink":"/docusaurus-test/docs/how-tos/airflow/run-dbt","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/how-tos/airflow/run-dbt.md","tags":[],"version":"current","sidebarPosition":28,"frontMatter":{"title":"DAGs - Run dbt","sidebar_position":28},"sidebar":"tutorialSidebar","previous":{"title":"DAGs - Run Airbyte sync jobs","permalink":"/docusaurus-test/docs/how-tos/airflow/run-airbyte-sync-jobs"},"next":{"title":"DAGs - Retry dbt jobs","permalink":"/docusaurus-test/docs/how-tos/airflow/retry-dbt-tasks"}}');var r=t(74848),s=t(28453);const i={title:"DAGs - Run dbt",sidebar_position:28},a="How to run dbt from an Airflow worker",d={},c=[{value:"Create a DAG that uses the script",id:"create-a-dag-that-uses-the-script",level:2},{value:"Lets create a DAG!",id:"lets-create-a-dag",level:3},{value:"Python version",id:"python-version",level:3},{value:"YAML version",id:"yaml-version",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"how-to-run-dbt-from-an-airflow-worker",children:"How to run dbt from an Airflow worker"})}),"\n",(0,r.jsxs)(n.p,{children:["Airflow synchronizes a git repository's ",(0,r.jsx)(n.a,{href:"/docusaurus-test/docs/how-tos/datacoves/how_to_environments#services-configuration",children:"configured git branch"})," every minute. (The branch specified in  the ",(0,r.jsx)(n.code,{children:"Git branch name"})," field in the environment's DAGs sync configuration)"]}),"\n",(0,r.jsxs)(n.p,{children:["To run ",(0,r.jsx)(n.code,{children:"dbt"})," commands easily, we provide a pre-configured virtual environment with the necessary python dependencies such as dbt. Our Airflow Operator also does the following automatically:"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Copies the cloned dbt project to a writable folder within the Airflow file system"}),"\n",(0,r.jsxs)(n.li,{children:["Runs ",(0,r.jsx)(n.code,{children:"dbt deps"})," if ",(0,r.jsx)(n.code,{children:"dbt_modules"})," and ",(0,r.jsx)(n.code,{children:"dbt_packages"})," folders do not exist"]}),"\n",(0,r.jsx)(n.li,{children:"Sets the current directory to the dbt_project_folder"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This means that you can simply run ",(0,r.jsx)(n.code,{children:"dbt <dbt subcommand>"})," in your Airflow DAG and we will handle the rest."]}),"\n",(0,r.jsx)(n.h2,{id:"create-a-dag-that-uses-the-script",children:"Create a DAG that uses the script"}),"\n",(0,r.jsxs)(n.p,{children:["If your dbt command like ",(0,r.jsx)(n.code,{children:"dbt run"})," works in your development environment(",(0,r.jsx)(n.strong,{children:"Try dbt run in your terminal"}),"), then you should be able to create an Airflow DAG that will run this command automatically."]}),"\n",(0,r.jsxs)(n.admonition,{type:"tip",children:[(0,r.jsx)(n.mdxAdmonitionTitle,{}),(0,r.jsxs)(n.p,{children:["Keep in mind that in an Airflow context ",(0,r.jsx)(n.code,{children:"dbt"})," is installed in an isolated Python Virtual Environment to avoid clashing with Airflow python dependencies. Datacoves default Python's virtualenv is located in ",(0,r.jsx)(n.code,{children:"/opt/datacoves/virtualenvs/main"}),". No need to worry about the complexity when using the ",(0,r.jsx)(n.code,{children:"@task.datacoves_dbt"})," decorator because it will automatically activate that environment amongst other actions."]}),(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.a,{href:"/docusaurus-test/docs/reference/airflow/datacoves-decorators",children:"Datacoves Decorators"})," for more information."]})]}),"\n",(0,r.jsx)(n.h3,{id:"lets-create-a-dag",children:"Lets create a DAG!"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 1:"})," If using Git Sync, switch to your configured branch (",(0,r.jsx)(n.code,{children:"airflow_development"})," or ",(0,r.jsx)(n.code,{children:"main"}),"), create a python file inside of ",(0,r.jsx)(n.code,{children:"orchestrate/dags"})," named ",(0,r.jsx)(n.code,{children:"my_sample_dag.py"})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 2:"})," Paste in the code below and be sure to replace information such as name, email and model name with your own."]}),"\n",(0,r.jsx)(n.h3,{id:"python-version",children:"Python version"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from pendulum import datetime\nfrom airflow.decorators import dag, task\n\n@dag(\n    default_args={\n        "start_date": datetime(2024, 1, 1),\n        "owner": "Noel Gomez",  # Replace with name\n        "email": "gomezn@example.com",  # Replace with your email\n        "email_on_failure": True,\n    },\n    description="Sample DAG for dbt run",\n    schedule="0 0 1 */12 *",  # Replace with your desired schedule\n    tags=["version_2"],\n    catchup=False,\n)\ndef my_sample_dag():\n\n    @task.datacoves_dbt(connection_id="main")\n    def run_dbt():\n        return "dbt run -s personal_loans"  # Replace with your model\n\n    run_dbt()\n\nmy_sample_dag()\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 3:"})," Push your changes to the branch."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 4:"})," Head over to Airflow in the Datacoves UI and refresh. It may take a minute but you should see your DAG populate."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Step 5:"})," Regardless of the schedule you set, the default during development is to have the DAG paused. You can trigger the DAG to see it in action or turn it on to test the schedule."]}),"\n",(0,r.jsx)(n.h3,{id:"yaml-version",children:"YAML version"}),"\n",(0,r.jsxs)(n.p,{children:["If you are making use of the ",(0,r.jsx)(n.code,{children:"dbt-coves generate airflow-dags"})," command, you can write DAGs using YML."]}),"\n",(0,r.jsx)(n.p,{children:"The name of the file will used as the DAG name."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:'description: "Sample DAG for dbt run"\nschedule: "0 0 1 */12 *"\ntags:\n  - version_2\ndefault_args:\n  start_date: 2024-01-01\n  owner: Noel Gomez # Replace with your name\n  # Replace with the email of the recipient for failures\n  email: gomezn@example.com \n  email_on_failure: true\ncatchup: false\n\nnodes:\n  run_dbt:\n    type: task\n    operator: operators.datacoves.dbt.DatacovesDbtOperator\n    bash_command: "dbt run -s personal_loans" # Replace with your model name\n'})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);