"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4659],{1777:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/airflow_databricks_connection-7dec6fb42e39b1c4363b8ee104fcda2c.png"},28453:(e,t,o)=>{o.d(t,{R:()=>a,x:()=>r});var s=o(96540);const n={},i=s.createContext(n);function a(e){const t=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:a(e.components),s.createElement(i.Provider,{value:t},e.children)}},43237:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/databricks_compute-ab8d10d6556a8cbf9496df7e4ec9a293.png"},47084:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/admin-connections-8f6e6d9caa31fe197b2f95b1b55f0de8.png"},63063:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"how-tos/airflow/run-databricks-notebook","title":"DAGs - Run Databricks Notebooks","description":"You can use Airflow in Datacoves to trigger a Databricks notebook. This guide will walk you through the configuration process.","source":"@site/docs/how-tos/airflow/run-databricks-notebook.md","sourceDirName":"how-tos/airflow","slug":"/how-tos/airflow/run-databricks-notebook","permalink":"/docusaurus-test/docs/how-tos/airflow/run-databricks-notebook","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/how-tos/airflow/run-databricks-notebook.md","tags":[],"version":"current","sidebarPosition":30,"frontMatter":{"title":"DAGs - Run Databricks Notebooks","sidebar_position":30},"sidebar":"tutorialSidebar","previous":{"title":"DAGs - Retry dbt jobs","permalink":"/docusaurus-test/docs/how-tos/airflow/retry-dbt-tasks"},"next":{"title":"DAGs - Run Fivetran sync jobs","permalink":"/docusaurus-test/docs/how-tos/airflow/run-fivetran-sync-jobs"}}');var n=o(74848),i=o(28453);const a={title:"DAGs - Run Databricks Notebooks",sidebar_position:30},r="Run Databricks Notebooks",c={},d=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"How to get Databricks Host and Databricks Cluster ID",id:"how-to-get-databricks-host-and-databricks-cluster-id",level:3},{value:"How to get Databricks Token",id:"how-to-get-databricks-token",level:3},{value:"How to get Databricks Notebook Path",id:"how-to-get-databricks-notebook-path",level:3},{value:"Handling Databricks Variables in Airflow",id:"handling-databricks-variables-in-airflow",level:2},{value:"Create a Databricks Connection in Airflow",id:"create-a-databricks-connection-in-airflow",level:2},{value:"Example DAG",id:"example-dag",level:2},{value:"Git Notebook as the source (Recommended)",id:"git-notebook-as-the-source-recommended",level:3},{value:"Understanding the Airflow DAG",id:"understanding-the-airflow-dag",level:2}];function l(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"run-databricks-notebooks",children:"Run Databricks Notebooks"})}),"\n",(0,n.jsx)(t.p,{children:"You can use Airflow in Datacoves to trigger a Databricks notebook. This guide will walk you through the configuration process."}),"\n",(0,n.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Databricks Host:"})," This is the URL of your Databricks cluster. It typically looks like ",(0,n.jsx)(t.code,{children:"https://<databricks-instance>.databricks.com"}),"."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Databricks Cluster ID:"})," This is the identifier of the cluster you want to use to run your notebook."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Databricks Token:"})," If you do not have admin privileges, work with an admin to get the token. Follow the ",(0,n.jsx)(t.a,{href:"https://docs.databricks.com/en/dev-tools/auth/pat.html",children:"Databricks documentation here"}),"."]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Databricks Notebook Repo Path:"})," This is the full path to the notebook you want to trigger from Airflow. We recommend using the Git Notebook feature in Databricks. This notebook is usually located in a Repos directory in Databricks."]}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"how-to-get-databricks-host-and-databricks-cluster-id",children:"How to get Databricks Host and Databricks Cluster ID"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 1:"})," Sign into your Databricks account."]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 2:"})," Navigate to compute."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"databricks compute",src:o(43237).A+"",width:"294",height:"390"})}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 3:"})," Click on your desired cluster."]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 4:"})," Scroll to ",(0,n.jsx)(t.code,{children:"Advanced Options"})," and ",(0,n.jsx)(t.code,{children:"JDBC/ODBC"}),". Copy the value under ",(0,n.jsx)(t.code,{children:"Server Hostname"}),". The host value will look something like this: ",(0,n.jsx)(t.code,{children:"<databricks-instance>.databricks.com"}),"."]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 5:"})," Scroll to ",(0,n.jsx)(t.code,{children:"Tags"})," and expand ",(0,n.jsx)(t.code,{children:"Automatically added tags"}),". Your ",(0,n.jsx)(t.code,{children:"ClusterId"})," should look something like this: ",(0,n.jsx)(t.code,{children:"0123-5678910-abcdefghijk"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"how-to-get-databricks-token",children:"How to get Databricks Token"}),"\n",(0,n.jsxs)(t.p,{children:["If you do not have admin privileges, work with an admin to get the token. Follow the ",(0,n.jsx)(t.a,{href:"https://docs.databricks.com/en/dev-tools/auth/pat.html",children:"Databricks documentation here"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"how-to-get-databricks-notebook-path",children:"How to get Databricks Notebook Path"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 1:"})," Navigate to your notebook in the Databricks user interface."]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 2:"})," To the right of the notebook name, there will be three dots. Click on this and select the option to copy the full path to your clipboard."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"copy url",src:o(65836).A+"",width:"902",height:"440"})}),"\n",(0,n.jsx)(t.h2,{id:"handling-databricks-variables-in-airflow",children:"Handling Databricks Variables in Airflow"}),"\n",(0,n.jsx)(t.p,{children:"It is best practice to use Airflow variables for values that may need to change in your Airflow DAG. This allows for easy updates without redeployment of your Airflow code."}),"\n",(0,n.jsx)(t.p,{children:"It is possible to hardcode these two variables in your DAG if you don\u2019t see them needing to be changed."}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"DATABRICKS_CLUSTER_ID"}),": Your databricks Cluster ID"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"MY_NOTEBOOK_REPO_PATH"}),": This should be a meaningful name as you may have many notebooks you wish to trigger eg) INSERT_INTO_RAW_REPO_PATH"]}),"\n"]}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 1:"})," A user with Airflow admin privileges must go to the Airflow ",(0,n.jsx)(t.code,{children:"Admin -> Variables"})," menu and add the variables and their values."]}),"\n",(0,n.jsx)(t.h2,{id:"create-a-databricks-connection-in-airflow",children:"Create a Databricks Connection in Airflow"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 1:"})," A user with Airflow admin privileges must go to the ",(0,n.jsx)(t.code,{children:"Airflow Admin -> Connection"})," menu."]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"admin connection",src:o(47084).A+"",width:"1126",height:"468"})}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 2:"})," Create a new connection using the following details:"]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Connection Id:"})," ",(0,n.jsx)(t.code,{children:"databricks_default"})," - this name will be used in your DAG"]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Connection Type:"})," ",(0,n.jsx)(t.code,{children:"Databricks"})]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Host:"})," Your Databricks host. E.g. ",(0,n.jsx)(t.code,{children:"https://<databricks-instance>.databricks.com"})]}),"\n",(0,n.jsxs)(t.li,{children:[(0,n.jsx)(t.strong,{children:"Password:"})," Enter your ",(0,n.jsx)(t.code,{children:"Databricks Token"})]}),"\n"]}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{alt:"Databricks Connection",src:o(1777).A+"",width:"870",height:"902"})}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Step 3:"})," Click ",(0,n.jsx)(t.code,{children:"Save"})]}),"\n",(0,n.jsx)(t.h2,{id:"example-dag",children:"Example DAG"}),"\n",(0,n.jsxs)(t.p,{children:["Once you have configured your Databricks connection and variables, you are ready to create your DAG. Head into the ",(0,n.jsx)(t.code,{children:"Transform"})," tab to begin writing your DAG inside the dags folder, e.g. ",(0,n.jsx)(t.code,{children:"orchestrate/dags"}),"."]}),"\n",(0,n.jsx)(t.h3,{id:"git-notebook-as-the-source-recommended",children:"Git Notebook as the source (Recommended)"}),"\n",(0,n.jsxs)(t.p,{children:["We recommend using a git as the source to leverage version control when developing notebooks. Be aware that if changes are made in the databricks tracked branch (",(0,n.jsx)(t.code,{children:"GIT_BRANCH"}),"), they will be executed in Airflow regardless if the changes are committed into Git. The best practice is to have users develop on feature branches and then merge to main."]}),"\n",(0,n.jsx)(t.pre,{children:(0,n.jsx)(t.code,{className:"language-python",children:'import os\nfrom datetime import datetime\nfrom airflow.models import Variable\nfrom airflow.decorators import dag\nfrom airflow.providers.databricks.operators.databricks import DatabricksSubmitRunDeferrableOperator\n\nDATABRICKS_CLUSTER_ID = Variable.get("DATABRICKS_CLUSTER_ID")\nMY_NOTEBOOK_REPO_PATH = "/PATH/TO/MY/NOTEBOOK"\nGIT_BRANCH = "main"  # Specify the branch you want to use\n\n@dag(\n    schedule="@daily",\n    start_date=datetime(2024, 1, 1),\n    tags=["version_1"],\n    catchup=False\n)\ndef databricks_example_run():\n\n    notebook_task_params = {\n        "task_key": "unique-task-key",\n        "notebook_task": {\n            "notebook_path": MY_NOTEBOOK_REPO_PATH,\n            "base_parameters": {\n                "branch": GIT_BRANCH  # Specify the branch in variable\n            }\n        },\n        "source": "GIT",\n        "existing_cluster_id": DATABRICKS_CLUSTER_ID,\n        "run_name": "databricks_workbook_run",  # Update with a unique name\n    }\n\n    DatabricksSubmitRunDeferrableOperator(\n        task_id="notebook_task",  # Rename with appropriate name\n        json=notebook_task_params,\n        databricks_conn_id="databricks_default"  # Must match databricks connection id set above\n    )\n\ndag = databricks_example_run()\n'})}),"\n",(0,n.jsx)(t.h2,{id:"understanding-the-airflow-dag",children:"Understanding the Airflow DAG"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["The DAG makes use of the ",(0,n.jsx)(t.a,{href:"https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/operators/submit_run.html",children:(0,n.jsx)(t.code,{children:"DatabricksSubmitRunDeferrableOperator"})})," which uses the ",(0,n.jsx)(t.a,{href:"https://docs.databricks.com/api/workspace/jobs/submit",children:"jobs/runs/submit"})," endpoint of the Databricks API. You can see the full list of options available by looking at the previous two links."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["We\u2019re passing a ",(0,n.jsx)(t.a,{href:"https://docs.databricks.com/api/workspace/jobs/submit#notebook_task",children:"Notebook task object"})," with the source set to ",(0,n.jsx)(t.code,{children:"GIT"}),", meaning the notebook will be retrieved from Databricks Repos, which is synced with a version-controlled Git repository. Alternatively, you can set the source to ",(0,n.jsx)(t.code,{children:"WORKSPACE"})," to pull the notebook code directly from the local Databricks workspace. Using ",(0,n.jsx)(t.code,{children:"GIT"})," is generally more reliable for production environments because it ensures that the notebook code is managed through a version-controlled system, providing consistency and traceability."]}),"\n"]}),"\n",(0,n.jsxs)(t.li,{children:["\n",(0,n.jsxs)(t.p,{children:["And lastly, we have customized the ",(0,n.jsx)(t.code,{children:"run_name"}),". In a non-example DAG, you would want this to be unique so you can better identify the runs in Airflow and Databricks."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},65836:(e,t,o)=>{o.d(t,{A:()=>s});const s=o.p+"assets/images/databricks_copyurl-75b6e3b6e5781f8ee163502b0e178b65.png"}}]);