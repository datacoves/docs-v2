"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1306],{18321:(e,o,n)=>{n.r(o),n.d(o,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"how-tos/airflow/customize-worker-environment","title":"How to set up a custom environment for your Airflow workers","description":"If you need to run tasks on Airflow on a custom environment that comes with pre-installed libraries and tools, we recommend building your own custom docker image, upload it to a docker image repository such as dockerhub and reference it in your DAG\'s task operator.","source":"@site/docs/how-tos/airflow/customize-worker-environment.md","sourceDirName":"how-tos/airflow","slug":"/how-tos/airflow/customize-worker-environment","permalink":"/docusaurus-test/docs/how-tos/airflow/customize-worker-environment","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/how-tos/airflow/customize-worker-environment.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"How to Add Docs at the DAG Level in Airflow","permalink":"/docusaurus-test/docs/how-tos/airflow/create-dag-level-docs"},"next":{"title":"How to Dynamically set the schedule Interval","permalink":"/docusaurus-test/docs/how-tos/airflow/dynamically-set-schedule"}}');var r=n(74848),s=n(28453);const a={},i="How to set up a custom environment for your Airflow workers",c={},d=[{value:"Using the custom image in your DAGs",id:"using-the-custom-image-in-your-dags",level:2},{value:"Python version",id:"python-version",level:3},{value:"YAML version",id:"yaml-version",level:3}];function l(e){const o={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(o.header,{children:(0,r.jsx)(o.h1,{id:"how-to-set-up-a-custom-environment-for-your-airflow-workers",children:"How to set up a custom environment for your Airflow workers"})}),"\n",(0,r.jsx)(o.p,{children:"If you need to run tasks on Airflow on a custom environment that comes with pre-installed libraries and tools, we recommend building your own custom docker image, upload it to a docker image repository such as dockerhub and reference it in your DAG's task operator."}),"\n",(0,r.jsx)(o.h2,{id:"using-the-custom-image-in-your-dags",children:"Using the custom image in your DAGs"}),"\n",(0,r.jsxs)(o.p,{children:["Every task in an Airflow DAG can use a different docker image. Operators accept an ",(0,r.jsx)(o.code,{children:"executor_config"})," argument that can be used to customize the executor context."]}),"\n",(0,r.jsxs)(o.p,{children:["Given that Datacoves runs Airflow on a kubernetes execution context, you need to pass a ",(0,r.jsx)(o.code,{children:"dict"})," with a ",(0,r.jsx)(o.code,{children:"pod_override"})," key that will override the worker pod's configuration, as seen in the ",(0,r.jsx)(o.code,{children:"TRANSFORM_CONFIG"})," dict in the example below. The variable name for the Config dict will depend on what DAG task you are requesting more resources for."]}),"\n",(0,r.jsxs)(o.p,{children:["eg) When writing your yaml, if you add the config under ",(0,r.jsx)(o.code,{children:" marketing_automation"})," the ",(0,r.jsx)(o.code,{children:"CONFIG"})," variable will be dynamically named ",(0,r.jsx)(o.code,{children:"MARKETING_AUTOMATION_CONFIG"}),". In the yml examples below, we added the config in a transform task so the ",(0,r.jsx)(o.code,{children:"CONFIG"})," variable is named ",(0,r.jsx)(o.code,{children:"TRANSFORM_CONFIG"}),"."]}),"\n",(0,r.jsx)(o.h3,{id:"python-version",children:"Python version"}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-python",children:'from pendulum import datetime\nfrom airflow.decorators import dag, task\nfrom kubernetes.client import models as k8s\n\nTRANSFORM_CONFIG = {\n    "pod_override": k8s.V1Pod(\n        spec=k8s.V1PodSpec(\n            containers=[\n                k8s.V1Container(\n                    name="base",\n                    image="<IMAGE REPO>:<IMAGE TAG>",\n                )\n            ]\n        )\n    ),\n}\n\n@dag(\n    default_args={\n        "start_date": datetime(2022, 10, 10),\n        "owner": "Noel Gomez",\n        "email": "gomezn@example.com",\n        "email_on_failure": True,\n    },\n    description="Sample DAG with custom image",\n    schedule="0 0 1 */12 *",  # Using \'schedule\' instead of deprecated \'schedule_interval\'\n    tags=["version_2"],\n    catchup=False,\n)\ndef yaml_teams_dag():\n\n    @task.datacoves_bash(executor_config=TRANSFORM_CONFIG)\n    def transform():\n        return "echo SUCCESS!"\n\n    transform()\n\nyaml_teams_dag()\n'})}),"\n",(0,r.jsx)(o.h3,{id:"yaml-version",children:"YAML version"}),"\n",(0,r.jsx)(o.p,{children:"In the yml dag you can configure the image."}),"\n",(0,r.jsx)(o.pre,{children:(0,r.jsx)(o.code,{className:"language-yaml",children:'description: "Sample DAG with custom image"\nschedule_interval: "0 0 1 */12 *"\ntags:\n  - version_2\ndefault_args:\n  start_date: 2022-10-10\n  owner: Noel Gomez\n  email: gomezn@example.com\n  email_on_failure: true\ncatchup: false\n\n# DAG Tasks\nnodes:\n  transform:\n    operator: operators.datacoves.bash.DatacovesBashOperator\n    type: task\n    config:\n      # Replace with your custom docker image <IMAGE REPO>:<IMAGE TAG>\n      image: <IMAGE REPO>:<IMAGE TAG>\n\n    bash_command: "echo SUCCESS!"\n'})})]})}function u(e={}){const{wrapper:o}={...(0,s.R)(),...e.components};return o?(0,r.jsx)(o,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}},28453:(e,o,n)=>{n.d(o,{R:()=>a,x:()=>i});var t=n(96540);const r={},s=t.createContext(r);function a(e){const o=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(o):{...o,...e}},[o,e])}function i(e){let o;return o=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:o},e.children)}}}]);