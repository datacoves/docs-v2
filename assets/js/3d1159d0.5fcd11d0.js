"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1306],{18321:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"how-tos/airflow/customize-worker-environment","title":"Worker - Custom Worker Environment","description":"If you need to run tasks on Airflow on a custom environment that comes with pre-installed libraries and tools, we recommend building your own custom docker image, upload it to a docker image repository such as dockerhub and reference it in your DAG\'s task operator.","source":"@site/docs/how-tos/airflow/customize-worker-environment.md","sourceDirName":"how-tos/airflow","slug":"/how-tos/airflow/customize-worker-environment","permalink":"/docusaurus-test/docs/how-tos/airflow/customize-worker-environment","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":39,"frontMatter":{"title":"Worker - Custom Worker Environment","sidebar_position":39},"sidebar":"tutorialSidebar","previous":{"title":"Secrets - Datacoves secrets manager","permalink":"/docusaurus-test/docs/how-tos/airflow/use-datacoves-secrets-manager"},"next":{"title":"Worker - Request Memory and CPU","permalink":"/docusaurus-test/docs/how-tos/airflow/request-resources-on-workers"}}');var t=o(74848),s=o(28453);const a={title:"Worker - Custom Worker Environment",sidebar_position:39},i="How to set up a custom environment for your Airflow workers",c={},d=[{value:"Using the custom image in your DAGs",id:"using-the-custom-image-in-your-dags",level:2},{value:"Python version",id:"python-version",level:3},{value:"YAML version",id:"yaml-version",level:3}];function l(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"how-to-set-up-a-custom-environment-for-your-airflow-workers",children:"How to set up a custom environment for your Airflow workers"})}),"\n",(0,t.jsx)(n.p,{children:"If you need to run tasks on Airflow on a custom environment that comes with pre-installed libraries and tools, we recommend building your own custom docker image, upload it to a docker image repository such as dockerhub and reference it in your DAG's task operator."}),"\n",(0,t.jsx)(n.h2,{id:"using-the-custom-image-in-your-dags",children:"Using the custom image in your DAGs"}),"\n",(0,t.jsxs)(n.p,{children:["Every task in an Airflow DAG can use a different docker image. Operators accept an ",(0,t.jsx)(n.code,{children:"executor_config"})," argument that can be used to customize the executor context."]}),"\n",(0,t.jsxs)(n.p,{children:["Given that Datacoves runs Airflow on a kubernetes execution context, you need to pass a ",(0,t.jsx)(n.code,{children:"dict"})," with a ",(0,t.jsx)(n.code,{children:"pod_override"})," key that will override the worker pod's configuration, as seen in the ",(0,t.jsx)(n.code,{children:"TRANSFORM_CONFIG"})," dict in the example below. The variable name for the Config dict will depend on what DAG task you are requesting more resources for."]}),"\n",(0,t.jsxs)(n.p,{children:["eg) When writing your yaml, if you add the config under ",(0,t.jsx)(n.code,{children:" marketing_automation"})," the ",(0,t.jsx)(n.code,{children:"CONFIG"})," variable will be dynamically named ",(0,t.jsx)(n.code,{children:"MARKETING_AUTOMATION_CONFIG"}),". In the yml examples below, we added the config in a transform task so the ",(0,t.jsx)(n.code,{children:"CONFIG"})," variable is named ",(0,t.jsx)(n.code,{children:"TRANSFORM_CONFIG"}),"."]}),"\n",(0,t.jsx)(n.h3,{id:"python-version",children:"Python version"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'from pendulum import datetime\nfrom airflow.decorators import dag, task\nfrom kubernetes.client import models as k8s\n\nTRANSFORM_CONFIG = {\n    "pod_override": k8s.V1Pod(\n        spec=k8s.V1PodSpec(\n            containers=[\n                k8s.V1Container(\n                    name="base",\n                    image="<IMAGE REPO>:<IMAGE TAG>",\n                )\n            ]\n        )\n    ),\n}\n\n@dag(\n    default_args={\n        "start_date": datetime(2022, 10, 10),\n        "owner": "Noel Gomez",\n        "email": "gomezn@example.com",\n        "email_on_failure": True,\n    },\n    description="Sample DAG with custom image",\n    schedule="0 0 1 */12 *",  # Using \'schedule\' instead of deprecated \'schedule_interval\'\n    tags=["version_2"],\n    catchup=False,\n)\ndef yaml_teams_dag():\n\n    @task.datacoves_bash(executor_config=TRANSFORM_CONFIG)\n    def transform():\n        return "echo SUCCESS!"\n\n    transform()\n\nyaml_teams_dag()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"yaml-version",children:"YAML version"}),"\n",(0,t.jsx)(n.p,{children:"In the yml dag you can configure the image."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",children:'description: "Sample DAG with custom image"\nschedule_interval: "0 0 1 */12 *"\ntags:\n  - version_2\ndefault_args:\n  start_date: 2022-10-10\n  owner: Noel Gomez\n  email: gomezn@example.com\n  email_on_failure: true\ncatchup: false\n\n# DAG Tasks\nnodes:\n  transform:\n    operator: operators.datacoves.bash.DatacovesBashOperator\n    type: task\n    config:\n      # Replace with your custom docker image <IMAGE REPO>:<IMAGE TAG>\n      image: <IMAGE REPO>:<IMAGE TAG>\n\n    bash_command: "echo SUCCESS!"\n'})})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>a,x:()=>i});var r=o(96540);const t={},s=r.createContext(t);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);