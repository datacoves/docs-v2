"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7402],{13709:(e,s,n)=>{n.d(s,{A:()=>t});const t=n.p+"assets/images/service_connection_main-2fa6e3315b9af8d2cea5a98c1ded4de8.jpg"},28453:(e,s,n)=>{n.d(s,{R:()=>d,x:()=>a});var t=n(96540);const o={},r=t.createContext(o);function d(e){const s=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function a(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:d(e.components),t.createElement(r.Provider,{value:s},e.children)}},77043:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>i,contentTitle:()=>a,default:()=>h,frontMatter:()=>d,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"reference/airflow/datacoves-decorators","title":"Datacoves Airflow Decorators","description":"With the introduction of the task flow API in Airflow we have released the Datacoves decorators to make writing DAGs simple!","source":"@site/docs/reference/airflow/datacoves-decorators.md","sourceDirName":"reference/airflow","slug":"/reference/airflow/datacoves-decorators","permalink":"/docusaurus-test/docs/reference/airflow/datacoves-decorators","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":125,"frontMatter":{"title":"Datacoves Airflow Decorators","sidebar_position":125},"sidebar":"tutorialSidebar","previous":{"title":"DAG Generators","permalink":"/docusaurus-test/docs/reference/airflow/dag-generators"},"next":{"title":"Datacoves CLI Commands","permalink":"/docusaurus-test/docs/reference/airflow/datacoves-commands"}}');var o=n(74848),r=n(28453);const d={title:"Datacoves Airflow Decorators",sidebar_position:125},a="Datacoves Airflow Decorators",i={},c=[{value:"Decorators",id:"decorators",level:2},{value:"@task.datacoves_bash",id:"taskdatacoves_bash",level:3},{value:"@task.datacoves_dbt",id:"taskdatacoves_dbt",level:3},{value:"Uploading and downloading dbt results",id:"uploading-and-downloading-dbt-results",level:4},{value:"@task.datacoves_airflow_db_sync",id:"taskdatacoves_airflow_db_sync",level:3}];function l(e){const s={a:"a",admonition:"admonition",br:"br",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(s.header,{children:(0,o.jsx)(s.h1,{id:"datacoves-airflow-decorators",children:"Datacoves Airflow Decorators"})}),"\n",(0,o.jsx)(s.p,{children:"With the introduction of the task flow API in Airflow we have released the Datacoves decorators to make writing DAGs simple!"}),"\n",(0,o.jsxs)(s.admonition,{type:"note",children:[(0,o.jsx)(s.mdxAdmonitionTitle,{}),(0,o.jsxs)(s.p,{children:["While the Datacoves decorators are recommended, the ",(0,o.jsx)(s.a,{href:"/docusaurus-test/docs/reference/airflow/datacoves-operator",children:"Datacoves Operators"}),", are still supported."]})]}),"\n",(0,o.jsx)(s.h2,{id:"decorators",children:"Decorators"}),"\n",(0,o.jsx)(s.h3,{id:"taskdatacoves_bash",children:"@task.datacoves_bash"}),"\n",(0,o.jsx)(s.p,{children:"This custom decorator is an extension of Airflow's default @task decorator and should be used to run bash commands, pull secrets etc."}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"The operator does the following:"})}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:["Copies the entire Datacoves repo to a temporary directory, to avoid read-only errors when running ",(0,o.jsx)(s.code,{children:"bash_command"}),"."]}),"\n",(0,o.jsx)(s.li,{children:"Activates the Datacoves Airflow virtualenv."}),"\n",(0,o.jsxs)(s.li,{children:["Runs the command in the repository root (or a passed ",(0,o.jsx)(s.code,{children:"cwd"}),", relative path from repo root where to run command from)."]}),"\n"]}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"Params:"})}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"env"}),": Pass in a dictionary of variables. eg ",(0,o.jsx)(s.code,{children:'"my_var": "{{ var.value.my_var }}"'}),".",(0,o.jsx)(s.br,{}),"\n","Please use ",(0,o.jsx)(s.code,{children:"{{ var.value.my_var }}"})," syntax to avoid parsing every 30 seconds."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"outlets"}),": Used to connect a task to an object in datahub or update a dataset"]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"append_env"}),": Add env vars to existing ones like ",(0,o.jsx)(s.code,{children:"DATACOVES__DBT_HOME"})]}),"\n"]}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-python",children:'def my_bash_dag():\n    @task.datacoves_bash\n    def echo_hello_world() -> str:\n        return "Hello World!"\ndag = my_bash_dag()\n'})}),"\n",(0,o.jsx)(s.h3,{id:"taskdatacoves_dbt",children:"@task.datacoves_dbt"}),"\n",(0,o.jsx)(s.p,{children:"This custom decorator is an extension of the @task decorator and simplifies running dbt commands within Airflow."}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"The operator does the following:"})}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:["Copies the entire Datacoves repo to a temporary directory, to avoid read-only errors when running ",(0,o.jsx)(s.code,{children:"bash_command"}),"."]}),"\n",(0,o.jsx)(s.li,{children:"It always activates the Datacoves Airflow virtualenv."}),"\n",(0,o.jsxs)(s.li,{children:["If ",(0,o.jsx)(s.code,{children:"dbt_packages"})," isn't found, it'll run ",(0,o.jsx)(s.code,{children:"dbt deps"})," before the desired command."]}),"\n",(0,o.jsx)(s.li,{children:"It runs dbt commands inside the dbt Project Root, not the Repository root."}),"\n"]}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"Params:"})}),"\n",(0,o.jsxs)(s.p,{children:["Datacoves dbt decorator supports all the ",(0,o.jsx)(s.a,{href:"./datacoves-operator#datacoves-dbt-operator",children:"Datacoves dbt Operator params"})," plus:"]}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"connection_id"}),": This is the ",(0,o.jsx)(s.a,{href:"/docusaurus-test/docs/how-tos/datacoves/how_to_service_connections",children:"service connection"})," which is automatically added to airflow if you select ",(0,o.jsx)(s.code,{children:"Airflow Connection"})," as the ",(0,o.jsx)(s.code,{children:"Delivery Mode"}),"."]}),"\n"]}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"dbt profile generation:"})}),"\n",(0,o.jsxs)(s.p,{children:["With the ",(0,o.jsx)(s.code,{children:"connection_id"})," mentioned above, we create a temporary dbt profile (it only exists at runtime inside the Airflow DAG's worker). By default, this dbt profile contains the selected Service Credential connection details."]}),"\n",(0,o.jsxs)(s.p,{children:["The dbt profile ",(0,o.jsx)(s.code,{children:"name"})," is defined either in Project or Environment settings, in their ",(0,o.jsx)(s.code,{children:"Profile name"})," field. This can be overwritten by passing a custom ",(0,o.jsx)(s.code,{children:"DATACOVES__DBT_PROFILE"})," environment variable to the decorator."]}),"\n",(0,o.jsx)(s.p,{children:"Users can also customize this dbt profile's connection details and/or target with the following params:"}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"overrides"}),": a dictionary with override parameters such as warehouse, role, database, etc."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"target"}),": the target name this temporary dbt profile will receive. Defaults to ",(0,o.jsx)(s.code,{children:"default"}),"."]}),"\n"]}),"\n",(0,o.jsx)(s.p,{children:"Basic example:"}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-python",children:'def my_dbt_dag():\n    @task.datacoves_dbt(\n      connection_id="main"\n    )\n    def dbt_test() -> str:\n        return "dbt debug"\n\ndag = my_dbt_dag()\n'})}),"\n",(0,o.jsx)(s.p,{children:"Example with overrides:"}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-python",children:'def my_dbt_dag():\n    @task.datacoves_dbt(\n        connection_id="main",\n        overrides={"warehouse": "my_custom_wh"},\n        env={"DATACOVES__DBT_PROFILE": "prod"},\n        target="testing"\n    )\n    def dbt_test() -> str:\n        return "dbt debug -t testing" # Make sure to pass `-t {target}` if you are using a custom target name.\n\ndag = my_dbt_dag()\n'})}),"\n",(0,o.jsxs)(s.p,{children:["The examples above use the Airflow connection ",(0,o.jsx)(s.code,{children:"main"})," which is added automatically from the Datacoves Service Connection."]}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.img,{alt:"Service Connection",src:n(13709).A+"",width:"2536",height:"1008"})}),"\n",(0,o.jsx)(s.h4,{id:"uploading-and-downloading-dbt-results",children:"Uploading and downloading dbt results"}),"\n",(0,o.jsxs)(s.p,{children:["From Datacoves 3.4 onwards, the ",(0,o.jsx)(s.code,{children:"datacoves_dbt"})," decorator allows users to upload and download dbt execution results and metadata to our ",(0,o.jsx)(s.code,{children:"dbt API"}),"."]}),"\n",(0,o.jsx)(s.admonition,{type:"note",children:(0,o.jsx)(s.p,{children:"dbt-API is a feature that is not enabled by default. Please contact support for further assistance."})}),"\n",(0,o.jsxs)(s.p,{children:["This is particularly useful for performing ",(0,o.jsx)(s.a,{href:"/docusaurus-test/docs/how-tos/airflow/retry-dbt-tasks",children:"dbt retries"}),"."]}),"\n",(0,o.jsx)(s.p,{children:"The new datacoves_dbt parameters are:"}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"dbt_api_enabled"})," (Default: ",(0,o.jsx)(s.code,{children:"False"}),"): Whether your Environment includes a dbt API instance."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"download_static_artifacts"})," (Default: ",(0,o.jsx)(s.code,{children:"True"}),"): Whether user wants to download dbt static artifact files."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"upload_static_artifacts"})," (Default: ",(0,o.jsx)(s.code,{children:"False"}),"): Whether user wants to upload dbt static files."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"download_additional_files"})," (Default: ",(0,o.jsx)(s.code,{children:"[]"}),"): A list of extra paths the user wants to download."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"upload_additional_files"})," (Default: ",(0,o.jsx)(s.code,{children:"[]"}),"): A list of extra paths the user wants to upload."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"upload_tag"})," (Default: DAG ",(0,o.jsx)(s.code,{children:"run_id"}),"): The tag/label the files will be uploaded with."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"upload_run_results"})," (Default: ",(0,o.jsx)(s.code,{children:"True"}),"): Whether the ",(0,o.jsx)(s.code,{children:"run_results.json"})," dbt file will be uploaded."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"download_run_results"})," (Default: ",(0,o.jsx)(s.code,{children:"False"}),"): Whether the ",(0,o.jsx)(s.code,{children:"run_results.json"})," dbt file will be downloaded."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"upload_sources_json"})," (Default: ",(0,o.jsx)(s.code,{children:"True"}),"): Whether the ",(0,o.jsx)(s.code,{children:"sources.json"})," dbt file will be uploaded."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"download_sources_json"})," (Default: ",(0,o.jsx)(s.code,{children:"False"}),"): Whether the ",(0,o.jsx)(s.code,{children:"sources.json"})," dbt file will be downloaded."]}),"\n"]}),"\n",(0,o.jsxs)(s.admonition,{type:"note",children:[(0,o.jsxs)(s.p,{children:[(0,o.jsx)(s.strong,{children:"Static Artifacts"}),(0,o.jsx)(s.br,{}),"\n","The static artifacts are important dbt-generated files that help with dbt's operations:"]}),(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"target/graph_summary.json"}),": Contains a summary of the DAG structure of your dbt project."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"target/graph.gpickle"}),": A serialized Python networkx graph object representing your dbt project's dependency graph."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"target/partial_parse.msgpack"}),": Used by dbt to speed up subsequent runs by storing parsed information."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"target/semantic_manifest.json"}),": Contains semantic information about your dbt project."]}),"\n"]}),(0,o.jsxs)(s.p,{children:["These files are downloaded by default (when ",(0,o.jsx)(s.code,{children:"download_static_artifacts=True"}),') and are tagged as "latest" when uploaded.']})]}),"\n",(0,o.jsx)(s.h3,{id:"taskdatacoves_airflow_db_sync",children:"@task.datacoves_airflow_db_sync"}),"\n",(0,o.jsx)(s.admonition,{type:"note",children:(0,o.jsxs)(s.p,{children:["The following Airflow tables are synced by default: ",(0,o.jsx)(s.code,{children:"ab_permission"}),", ",(0,o.jsx)(s.code,{children:"ab_role"}),", ",(0,o.jsx)(s.code,{children:"ab_user"}),", ",(0,o.jsx)(s.code,{children:"dag"}),", ",(0,o.jsx)(s.code,{children:"dag_run"}),", ",(0,o.jsx)(s.code,{children:"dag_tag"}),", ",(0,o.jsx)(s.code,{children:"import_error"}),", ",(0,o.jsx)(s.code,{children:"job"}),", ",(0,o.jsx)(s.code,{children:"task_fail"}),", ",(0,o.jsx)(s.code,{children:"task_instance"}),"."]})}),"\n",(0,o.jsx)(s.p,{children:(0,o.jsx)(s.strong,{children:"Params:"})}),"\n",(0,o.jsxs)(s.ul,{children:["\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"db_type"}),": The data warehouse you are using. Currently supports ",(0,o.jsx)(s.code,{children:"redshift"})," or ",(0,o.jsx)(s.code,{children:"snowflake"}),"."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"destination_schema"}),": The destination schema where the Airflow tables will end up. By default, the schema will be named as follows: ",(0,o.jsx)(s.code,{children:"airflow-{datacoves environment slug}"}),", for example ",(0,o.jsx)(s.code,{children:"airflow-qwe123"}),"."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"connection_id"}),": The name of your Airflow ",(0,o.jsx)(s.a,{href:"/docusaurus-test/docs/how-tos/datacoves/how_to_service_connections",children:"service connection"})," which is automatically added to airflow if you select ",(0,o.jsx)(s.code,{children:"Airflow Connection"})," as the ",(0,o.jsx)(s.code,{children:"Delivery Mode"}),"."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"additional_tables"}),": A list of additional tables you would want to add to the default set."]}),"\n",(0,o.jsxs)(s.li,{children:[(0,o.jsx)(s.code,{children:"tables"}),": A list of tables to override the default ones from above. Warning: An empty list ",(0,o.jsx)(s.code,{children:"[]"})," will perform a full-database sync."]}),"\n"]}),"\n",(0,o.jsx)(s.pre,{children:(0,o.jsx)(s.code,{className:"language-python",children:'def airflow_data_sync():\n    @task.datacoves_airflow_db_sync(\n        db_type="snowflake",\n        destination_schema="airflow_dev", \n        connection_id="load_airflow",\n        # additional_tables=["additional_table_1", "additional_table_2"]\n    )\n\ndag = airflow_data_sync()\n'})})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,o.jsx)(s,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}}}]);