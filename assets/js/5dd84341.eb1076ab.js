"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7402],{13709:(e,s,n)=>{n.d(s,{A:()=>o});const o=n.p+"assets/images/service_connection_main-2fa6e3315b9af8d2cea5a98c1ded4de8.jpg"},28453:(e,s,n)=>{n.d(s,{R:()=>d,x:()=>r});var o=n(96540);const t={},a=o.createContext(t);function d(e){const s=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(s):{...s,...e}},[s,e])}function r(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:d(e.components),o.createElement(a.Provider,{value:s},e.children)}},77043:(e,s,n)=>{n.r(s),n.d(s,{assets:()=>i,contentTitle:()=>r,default:()=>h,frontMatter:()=>d,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"reference/airflow/datacoves-decorators","title":"Datacoves Airflow Decorators","description":"With the introduction of the task flow API in Airflow we have released the Datacoves decorators to make writing DAGs simple!","source":"@site/docs/reference/airflow/datacoves-decorators.md","sourceDirName":"reference/airflow","slug":"/reference/airflow/datacoves-decorators","permalink":"/docusaurus-test/docs/reference/airflow/datacoves-decorators","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/reference/airflow/datacoves-decorators.md","tags":[],"version":"current","sidebarPosition":125,"frontMatter":{"title":"Datacoves Airflow Decorators","sidebar_position":125},"sidebar":"tutorialSidebar","previous":{"title":"DAG Generators","permalink":"/docusaurus-test/docs/reference/airflow/dag-generators"},"next":{"title":"Datacoves CLI Commands","permalink":"/docusaurus-test/docs/reference/airflow/datacoves-commands"}}');var t=n(74848),a=n(28453);const d={title:"Datacoves Airflow Decorators",sidebar_position:125},r="Datacoves Airflow Decorators",i={},c=[{value:"Decorators",id:"decorators",level:2},{value:"@task.datacoves_bash",id:"taskdatacoves_bash",level:3},{value:"@task.datacoves_dbt",id:"taskdatacoves_dbt",level:3},{value:"Uploading and downloading dbt results",id:"uploading-and-downloading-dbt-results",level:4},{value:"@task.datacoves_airflow_db_sync",id:"taskdatacoves_airflow_db_sync",level:3}];function l(e){const s={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(s.header,{children:(0,t.jsx)(s.h1,{id:"datacoves-airflow-decorators",children:"Datacoves Airflow Decorators"})}),"\n",(0,t.jsx)(s.p,{children:"With the introduction of the task flow API in Airflow we have released the Datacoves decorators to make writing DAGs simple!"}),"\n",(0,t.jsx)(s.admonition,{type:"note",children:(0,t.jsxs)(s.p,{children:["While the Datacoves decorators are recommended, the ",(0,t.jsx)(s.a,{href:"/docusaurus-test/docs/reference/airflow/datacoves-operator",children:"Datacoves Operators"}),", are still supported."]})}),"\n",(0,t.jsx)(s.p,{children:":::"}),"\n",(0,t.jsx)(s.h2,{id:"decorators",children:"Decorators"}),"\n",(0,t.jsx)(s.h3,{id:"taskdatacoves_bash",children:"@task.datacoves_bash"}),"\n",(0,t.jsx)(s.p,{children:"This custom decorator is an extension of Airflow's default @task decorator and should be used to run bash commands, pull secrets etc."}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"The operator does the following:"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["Copies the entire Datacoves repo to a temporary directory, to avoid read-only errors when running ",(0,t.jsx)(s.code,{children:"bash_command"}),"."]}),"\n",(0,t.jsx)(s.li,{children:"Activates the Datacoves Airflow virtualenv."}),"\n",(0,t.jsxs)(s.li,{children:["Runs the command in the repository root (or a passed ",(0,t.jsx)(s.code,{children:"cwd"}),", relative path from repo root where to run command from)."]}),"\n"]}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Params:"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.code,{children:"env"}),": Pass in a dictionary of variables. eg) ",(0,t.jsx)(s.code,{children:'"my_var": "{{ var.value.my_var }}"'}),". Please use ",(0,t.jsx)(s.code,{children:"{{ var.value.my_var }}"})," syntax to avoid parsing every 30 seconds."]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.code,{children:"outlets"}),": Used to connect a task to an object in datahub or update a dataset"]}),"\n"]}),"\n",(0,t.jsxs)(s.li,{children:["\n",(0,t.jsxs)(s.p,{children:[(0,t.jsx)(s.code,{children:"append_env"}),": Add env vars to existing ones like ",(0,t.jsx)(s.code,{children:"DATACOVES__DBT_HOME"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def my_bash_dag():\n    @task.datacoves_bash\n    def echo_hello_world() -> str:\n        return "Hello World!"\ndag = my_bash_dag()\n'})}),"\n",(0,t.jsx)(s.h3,{id:"taskdatacoves_dbt",children:"@task.datacoves_dbt"}),"\n",(0,t.jsx)(s.p,{children:"This custom decorator is an extension of the @task decorator and simplifies running dbt commands within Airflow."}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"The operator does the following:"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:["Copies the entire Datacoves repo to a temporary directory, to avoid read-only errors when running ",(0,t.jsx)(s.code,{children:"bash_command"}),"."]}),"\n",(0,t.jsx)(s.li,{children:"It always activates the Datacoves Airflow virtualenv."}),"\n",(0,t.jsxs)(s.li,{children:["If 'dbt_packages' isn't found, it'll run ",(0,t.jsx)(s.code,{children:"dbt deps"})," before the desired command"]}),"\n",(0,t.jsx)(s.li,{children:"It runs dbt commands inside the dbt Project Root, not the Repository root."}),"\n"]}),"\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Params:"})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"connection_id"}),": This is the ",(0,t.jsx)(s.a,{href:"/docusaurus-test/docs/how-tos/datacoves/how_to_service_connections",children:"service connection"})," which is automatically added to airflow if you select ",(0,t.jsx)(s.code,{children:"Airflow Connection"})," as the ",(0,t.jsx)(s.code,{children:"Delivery Mode"}),"."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"overrides"}),": Pass in a dictionary with override parameters such as warehouse, role, or database."]}),"\n"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def my_dbt_dag():\n    @task.datacoves_dbt(\n      connection_id="main"\n    )\n    def dbt_test() -> str:\n        return "dbt debug"\n\ndag = my_dbt_dag()\n'})}),"\n",(0,t.jsx)(s.p,{children:"Example with overrides."}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def my_dbt_dag():\n    @task.datacoves_dbt(\n        connection_id="main",\n        overrides={"warehouse": "my_custom_wh"})\n    def dbt_test() -> str:\n        return "dbt debug"\n\ndag = my_dbt_dag()\n'})}),"\n",(0,t.jsxs)(s.p,{children:["The examples above use the Airflow connection ",(0,t.jsx)(s.code,{children:"main"})," which is added automatically from the Datacoves Service Connection\n",(0,t.jsx)(s.img,{alt:"Service Connection",src:n(13709).A+"",width:"2536",height:"1008"})]}),"\n",(0,t.jsx)(s.h4,{id:"uploading-and-downloading-dbt-results",children:"Uploading and downloading dbt results"}),"\n",(0,t.jsxs)(s.p,{children:["From Datacoves 3.4 onwards, the ",(0,t.jsx)(s.code,{children:"datacoves_dbt"})," decorator allows users to upload and download dbt execution results and metadata to our ",(0,t.jsx)(s.code,{children:"dbt API"})]}),"\n",(0,t.jsx)(s.admonition,{type:"note",children:(0,t.jsx)(s.p,{children:"dbt-API is a feature that is not enabled by default. Please contact support for further assistance."})}),"\n",(0,t.jsxs)(s.p,{children:[":::\nThis is particularly useful for performing ",(0,t.jsx)(s.a,{href:"/docusaurus-test/docs/how-tos/airflow/retry-dbt-tasks",children:"dbt retries"}),"."]}),"\n",(0,t.jsx)(s.p,{children:"The new datacoves_dbt parameters are:"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"dbt_api_enabled"})," (Default: ",(0,t.jsx)(s.code,{children:"False"}),"): Whether your Environment includes a dbt API instance."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"download_static_artifacts"})," (Default: ",(0,t.jsx)(s.code,{children:"True"}),"): Whether user wants to download dbt static artifact files."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"upload_static_artifacts"})," (Default: ",(0,t.jsx)(s.code,{children:"False"}),"): Whether user wants to upload dbt static files."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"download_additional_files"})," (Default: ",(0,t.jsx)(s.code,{children:"[]"}),"): A list of extra paths the user wants to download."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"upload_additional_files"})," (Default: ",(0,t.jsx)(s.code,{children:"[]"}),"): A list of extra paths the user wants to upload."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"upload_tag"})," (Default: DAG ",(0,t.jsx)(s.code,{children:"run_id"}),"): The tag/label the files will be uploaded with."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"upload_run_results"})," (Default: ",(0,t.jsx)(s.code,{children:"True"}),"): Whether the ",(0,t.jsx)(s.code,{children:"run_results.json"})," dbt file will be uploaded."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"download_run_results"})," (Default: ",(0,t.jsx)(s.code,{children:"False"}),"): Whether the ",(0,t.jsx)(s.code,{children:"run_results.json"})," dbt file will be downloaded."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"upload_sources_json"})," (Default: ",(0,t.jsx)(s.code,{children:"True"}),"): Whether the ",(0,t.jsx)(s.code,{children:"sources.json"})," dbt file will be uploaded."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"download_sources_json"})," (Default: ",(0,t.jsx)(s.code,{children:"False"}),"): Whether the ",(0,t.jsx)(s.code,{children:"sources.json"})," dbt file will be downloaded."]}),"\n"]}),"\n",(0,t.jsx)(s.admonition,{type:"note",children:(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Static Artifacts"})}),"\n"]})}),"\n",(0,t.jsxs)(s.blockquote,{children:["\n",(0,t.jsx)(s.p,{children:"The static artifacts are important dbt-generated files that help with dbt's operations:"}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"target/graph_summary.json"}),": Contains a summary of the DAG structure of your dbt project."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"target/graph.gpickle"}),": A serialized Python networkx graph object representing your dbt project's dependency graph."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"target/partial_parse.msgpack"}),": Used by dbt to speed up subsequent runs by storing parsed information."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"target/semantic_manifest.json"}),": Contains semantic information about your dbt project."]}),"\n"]}),"\n",(0,t.jsxs)(s.p,{children:["These files are downloaded by default (when ",(0,t.jsx)(s.code,{children:"download_static_artifacts=True"}),') and are tagged as "latest" when uploaded.\n:::']}),"\n"]}),"\n",(0,t.jsx)(s.h3,{id:"taskdatacoves_airflow_db_sync",children:"@task.datacoves_airflow_db_sync"}),"\n",(0,t.jsx)(s.admonition,{title:"The following Airflow tables are synced by default: ab_permission, ab_role, ab_user, dag, dag_run, dag_tag, import_error, job, task_fail, task_instance.",type:"note",children:(0,t.jsx)(s.p,{children:(0,t.jsx)(s.strong,{children:"Params:"})})}),"\n",(0,t.jsxs)(s.ul,{children:["\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"db_type"}),": The data warehouse you are using. Currently supports ",(0,t.jsx)(s.code,{children:"redshift"})," or ",(0,t.jsx)(s.code,{children:"snowflake"}),"."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"destination_schema"}),": The destination schema where the Airflow tables will end-up. By default, the schema will be named as follows: ",(0,t.jsx)(s.code,{children:"airflow-{datacoves environment slug}"})," for example ",(0,t.jsx)(s.code,{children:"airflow-qwe123"}),"."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"connection_id"}),": The name of your Airflow ",(0,t.jsx)(s.a,{href:"/docusaurus-test/docs/how-tos/datacoves/how_to_service_connections",children:"service connection"})," which is automatically added to airflow if you select ",(0,t.jsx)(s.code,{children:"Airflow Connection"})," as the ",(0,t.jsx)(s.code,{children:"Delivery Mode"}),"."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"additional_tables"}),": A list of additional tables you would want to add to the default set."]}),"\n",(0,t.jsxs)(s.li,{children:[(0,t.jsx)(s.code,{children:"tables"}),": A list of tables to override the default ones from above. Warning: An empty list [] will perform a full-database sync."]}),"\n"]}),"\n",(0,t.jsx)(s.pre,{children:(0,t.jsx)(s.code,{className:"language-python",children:'def airflow_data_sync():\n    @task.datacoves_airflow_db_sync(\n        db_type="snowflake",\n        destination_schema="airflow_dev", \n        connection_id="load_airflow",\n        # additional_tables=["additional_table_1", "additional_table_2"]\n    )\n\ndag = airflow_data_sync()\n'})})]})}function h(e={}){const{wrapper:s}={...(0,a.R)(),...e.components};return s?(0,t.jsx)(s,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}}}]);